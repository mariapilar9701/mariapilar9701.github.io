<!DOCTYPE html>
<html lang="en">
<meta charset="UTF-8">
<title>Resources</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<link rel="stylesheet" href="../styles/styles.css">
<body>
<section class="resources">
<h3>Intersectionality</h3>
    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<h3>Implicit Bias</h3>
    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<h3>Implicit Bias Test</h3>
<h3>Additional Resources</h3>
<div>
    <h4>Joy Buolamwini TED Talk – How I’m fighting bias in algorithms</h4>
    <p>Joy Buolamwini is a black, female computer scientist whose career shifted focus upon her graduate studies at MIT. She had faced issues throughout her academic and professional career related to racially biased facial recognition software. This sort of algorithmic bias dates to the first camera, and how lighting settings were adjusted for white, or fair-skinned people. Now, this bias has caused issues in so many aspects of our lives such as criminal justice and hiring practices. The more artificial intelligence software is used across industries, the larger the magnitude of what Joy calls the “coded gaze” is. Joy has started the Algorithmic Justice League (https://www.ajl.org/) a movement toward “equitable and accountable AI” with innumerous efforts to better these systems we so heavily rely on.</p>
</div>
<div class="ai-resources">
    <div><h4>IBM AI Fairness 360</h4>
<p>A research-developed toolkit you can install on your devices to measure and lessen the bias within the algorithms you use. It available in Python or R code and uses over seventy different measures of individual and group fairness.
</p></div>
    <div><h4>AI and Climate Justice: Balancing Risk With Opportunity</h4>
<p>This article outlines the impacts that large-scale artificial intelligence data centers have on surrounding environments and communities, especially in an age of exponentiated data consumption. To ensure ethical and sustainable guidelines within this technological era, the relationships between computers and our natural world must be researched and placed more importance upon.
</p></div>


</div>
</section>
 IBT, intersectionality, and implicit bias

<section class="navigation">
    <button>
        <a href="../pages/techhero.html">
        <img src="../images/arrow-left.svg"/>
        Tech Heroes
        </a>
    </button>
    <h2>Resources</h2>
    <button>
    <a href="../index.html">
       Home
        <img src="../images/arrow-right.svg"/>
    </a>
    </button>
</section>
</body>

</html>